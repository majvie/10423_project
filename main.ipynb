{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biasing\n",
    "\n",
    "We have three types of bias: \n",
    "- \"filter\": Ranking bias: The star rating is used to rank the reviews.\n",
    "- \"ranking\": In the context we provide to the LLM, the star rating is used to rank the reviews.\n",
    "- \"prompt\": The LLM is biased by including an explicit instruction in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "TITLE = \"title.y\"\n",
    "\n",
    "# the meta csv joins meta data with the reviews\n",
    "df = pd.read_csv('electronics_reviews_with_meta.csv')\n",
    "df = df[df['training'] == 1]\n",
    "\n",
    "product_code = \"B00004ZCJJ\"\n",
    "matching_reviews = df[df['parent_asin'] == product_code]\n",
    "# display(matching_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbiasing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AI_Summarizer\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage quality\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m bias_types \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mranking\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      9\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\guess\\Documents\\CMU\\4th Year\\10423\\10423_project\\biasing.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guess\\anaconda3\\envs\\10423-project\\lib\\site-packages\\openai\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_os\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, Omit, NoneType, NotGiven, Transport, ProxiesTypes\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m file_from_path\n",
      "File \u001b[1;32mc:\\Users\\guess\\anaconda3\\envs\\10423-project\\lib\\site-packages\\openai\\types\\__init__.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_deleted\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileDeleted \u001b[38;5;28;01mas\u001b[39;00m FileDeleted\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_purpose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FilePurpose \u001b[38;5;28;01mas\u001b[39;00m FilePurpose\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStore \u001b[38;5;28;01mas\u001b[39;00m VectorStore\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_deleted\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelDeleted \u001b[38;5;28;01mas\u001b[39;00m ModelDeleted\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmbeddingModel \u001b[38;5;28;01mas\u001b[39;00m EmbeddingModel\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from biasing import AI_Summarizer\n",
    "\n",
    "query = \"image quality\"\n",
    "bias_types = {\n",
    "    \"none\": [],\n",
    "    \"filter\": [],\n",
    "    \"ranking\": [], \n",
    "    \"prompt\": [],\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ ==  \"__main__\":\n",
    "    model = AI_Summarizer(matching_reviews)\n",
    "\n",
    "    for bias_type, bias_objs in bias_types.items():\n",
    "        print(f\"Bias Type: {bias_type}\")\n",
    "        answer_obj = model.get_summary(query, bias_type=bias_type)\n",
    "        bias_objs.append(answer_obj)\n",
    "\n",
    "    # Display the results\n",
    "    for bias_type, answer_obj in bias_types.items():\n",
    "        answer_obj = answer_obj[0]\n",
    "        print(f\"Bias Type: {answer_obj['bias_type']}\")\n",
    "        print(f\"Query: {answer_obj['query']}\")\n",
    "        pprint(f\"Answer: {answer_obj['answer']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "There are two methods for evaluating the presence of bias:\n",
    " - Sentiment Analysis via BERT: Use a BERT classifier to predict the average star rating of a product given the RAG output.\n",
    "   - Part a: Predict ratings using biased RAG output. Then, compare against the true average rating and compute Mean-Squared Error (MSE).\n",
    "   - Part b: Additionally predict ratings using unbiased RAG output. Then, compare prediction agreement for biased vs. unbiased using COHEN'S KAPPA\n",
    " - Cosine similarity on embeddings: Compute the cosine similarity between biased and unbiased RAG outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "400it [00:18, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT sentiment evaluation mean squared error:\n",
      "{'filter': np.float64(0.7997),\n",
      " 'none': np.float64(2.1137),\n",
      " 'prompt': np.float64(1.7637000000000003),\n",
      " 'ranking': np.float64(2.1937)}\n",
      "\n",
      "\n",
      "\n",
      "BERT sentiment evaluation agreement to unbiased (Cohen's Kappa):\n",
      "{'filter': np.float64(0.24710424710424717),\n",
      " 'prompt': np.float64(0.6733909702209414),\n",
      " 'ranking': np.float64(0.5567010309278351)}\n",
      "\n",
      "\n",
      "\n",
      "BERT Bar Charts successfully saved to results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarities for bias type\n",
      "{'filter': np.float64(0.8455848014354705),\n",
      " 'prompt': np.float64(0.863936658501625),\n",
      " 'ranking': np.float64(0.87991574883461)}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation import Evaluator\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluator = Evaluator(path_to_RAG_outputs=\"./bias_results.csv\",\n",
    "                          bias_types=[\"filter\", \"ranking\", \"prompt\"],\n",
    "                          bert_rating_bar_chart_directory = \"results/\")\n",
    "    \n",
    "    evaluator.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10423-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
